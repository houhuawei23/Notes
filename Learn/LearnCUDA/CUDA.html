
<!DOCTYPE HTML>
<html lang="cn" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Learn CUDA Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-chapter-fold/chapter-fold.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-prism/prism-synthwave84.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-katex-pp/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-theme-comscore/test.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../LearnCV/ComputerVisoin.html" />
    
    
    <link rel="prev" href="../LearnConda/Conda.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../Learn.html">
            
                <a href="../Learn.html">
            
                    
                    Learn
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../LearnAIMA/">
            
                <a href="../LearnAIMA/">
            
                    
                    Learn AIMA
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../LearnConda/Conda.html">
            
                <a href="../LearnConda/Conda.html">
            
                    
                    Learn Conda
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.3" data-path="CUDA.html">
            
                <a href="CUDA.html">
            
                    
                    Learn CUDA
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../LearnCV/ComputerVisoin.html">
            
                <a href="../LearnCV/ComputerVisoin.html">
            
                    
                    Learn Computer Vision
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="../LearnDocker/docker.html">
            
                <a href="../LearnDocker/docker.html">
            
                    
                    Learn Docker
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="../LearnDrones/Note.html">
            
                <a href="../LearnDrones/Note.html">
            
                    
                    Learn Drones
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="../LearnGameDev/Note.html">
            
                <a href="../LearnGameDev/Note.html">
            
                    
                    Learn GameDev
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="../LearnGameTheory/GameTheory.html">
            
                <a href="../LearnGameTheory/GameTheory.html">
            
                    
                    Learn Game Theory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.9" data-path="../LearnLalrpop/Lalrpop.html">
            
                <a href="../LearnLalrpop/Lalrpop.html">
            
                    
                    Learn Lalrpop (Rust)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.10" data-path="../LearnPest/pest.html">
            
                <a href="../LearnPest/pest.html">
            
                    
                    Learn Pest (Rust)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.11" data-path="../LearnMLIR/MLIR-LanRef.html">
            
                <a href="../LearnMLIR/MLIR-LanRef.html">
            
                    
                    Learn MLIR
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.12" data-path="../LearnRust/Resources.html">
            
                <a href="../LearnRust/Resources.html">
            
                    
                    Learn Rust
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.13" data-path="../LearnROS/ROS.html">
            
                <a href="../LearnROS/ROS.html">
            
                    
                    Learn ROS
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.14" data-path="../PersonalWebsite/Note.html">
            
                <a href="../PersonalWebsite/Note.html">
            
                    
                    Learn Personal Website
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.15" data-path="../LearnMocCUDA/MocCUDA.html">
            
                <a href="../LearnMocCUDA/MocCUDA.html">
            
                    
                    Learn MocCUDA
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.16" data-path="../LearnPolygeist/Note.html">
            
                <a href="../LearnPolygeist/Note.html">
            
                    
                    Learn Polygeist
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.17" data-path="../LearnPolyhedralModel/Note.html">
            
                <a href="../LearnPolyhedralModel/Note.html">
            
                    
                    Learn Polyhedral Compilation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.18" data-path="../LearnROCm/ROCm.html">
            
                <a href="../LearnROCm/ROCm.html">
            
                    
                    Learn ROCm
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.19" data-path="../LearnJinJia2/Jinjia2.html">
            
                <a href="../LearnJinJia2/Jinjia2.html">
            
                    
                    Learn JinJia2
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../../Misc/Misc.html">
            
                <a href="../../Misc/Misc.html">
            
                    
                    Misc
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../../Misc/00_Links.html">
            
                <a href="../../Misc/00_Links.html">
            
                    
                    Useful Links
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../../Misc/01_GitHubReps.html">
            
                <a href="../../Misc/01_GitHubReps.html">
            
                    
                    Github Reps
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../../Misc/GitBook.html">
            
                <a href="../../Misc/GitBook.html">
            
                    
                    Gitbook
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../../Misc/Typst.html">
            
                <a href="../../Misc/Typst.html">
            
                    
                    Typst
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../../Misc/Markdown.html">
            
                <a href="../../Misc/Markdown.html">
            
                    
                    Markdown
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../../Misc/VScode.html">
            
                <a href="../../Misc/VScode.html">
            
                    
                    VScode
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="../../Misc/Bochs.html">
            
                <a href="../../Misc/Bochs.html">
            
                    
                    Bochs
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.8" data-path="../../Misc/RegularExp.html">
            
                <a href="../../Misc/RegularExp.html">
            
                    
                    Regular Exp
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.9" data-path="../../Misc/FuzzTesting/FuzzTesting.html">
            
                <a href="../../Misc/FuzzTesting/FuzzTesting.html">
            
                    
                    FuzzTesting
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.10" data-path="../../Misc/PowerShell.html">
            
                <a href="../../Misc/PowerShell.html">
            
                    
                    PowerShell
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.11" data-path="../../Misc/NPM.html">
            
                <a href="../../Misc/NPM.html">
            
                    
                    NPM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.12" data-path="../../Misc/Fonts.html">
            
                <a href="../../Misc/Fonts.html">
            
                    
                    Fonts
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.13" data-path="../../Misc/Drawing.html">
            
                <a href="../../Misc/Drawing.html">
            
                    
                    Drawing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.14" data-path="../../Misc/Flatpack">
            
                <span>
            
                    
                    Flatpack
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../../Linux/Linux.html">
            
                <a href="../../Linux/Linux.html">
            
                    
                    Linux
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../../Linux/Display/Display.html">
            
                <a href="../../Linux/Display/Display.html">
            
                    
                    Display
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../../Linux/LinuxFamily/LinuxFamily.html">
            
                <a href="../../Linux/LinuxFamily/LinuxFamily.html">
            
                    
                    LinuxFamily
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../../Linux/UserManagement.html">
            
                <a href="../../Linux/UserManagement.html">
            
                    
                    UserManagement
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../../Linux/InputMethod.html">
            
                <a href="../../Linux/InputMethod.html">
            
                    
                    InputMethod
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../../Linux/PrintingDrivers.html">
            
                <a href="../../Linux/PrintingDrivers.html">
            
                    
                    PrintingDrivers
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../../PythonLibs/PythonLibs.html">
            
                <a href="../../PythonLibs/PythonLibs.html">
            
                    
                    PythonLibs
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../../PythonLibs/ArgParse.html">
            
                <a href="../../PythonLibs/ArgParse.html">
            
                    
                    ArgParse
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../../Network/Network.html">
            
                <a href="../../Network/Network.html">
            
                    
                    Network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../../Network/Tailscale.html">
            
                <a href="../../Network/Tailscale.html">
            
                    
                    Tailscale
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../../Network/Clash.html">
            
                <a href="../../Network/Clash.html">
            
                    
                    Cxxxh
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" >
            
                <span>
            
                    
                    Git
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../../Git/git.html">
            
                <a href="../../Git/git.html">
            
                    
                    git
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../../Git/githttps.html">
            
                <a href="../../Git/githttps.html">
            
                    
                    githttps
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="../../Git/git-branch.html">
            
                <a href="../../Git/git-branch.html">
            
                    
                    git-branch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="../../Git/Github.html">
            
                <a href="../../Git/Github.html">
            
                    
                    GitHub
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../../Papers/Papers.html">
            
                <a href="../../Papers/Papers.html">
            
                    
                    Papers
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../../Papers/AttentionIsTuringComplete.html">
            
                <a href="../../Papers/AttentionIsTuringComplete.html">
            
                    
                    Attention Is Turing Complete
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../../Programming/Programming.html">
            
                <a href="../../Programming/Programming.html">
            
                    
                    Programming
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../../ConfigExamples/ConfigExamples.html">
            
                <a href="../../ConfigExamples/ConfigExamples.html">
            
                    
                    ConfigExamples
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="../../ReadingNotes/ReadingNotes.html">
            
                <a href="../../ReadingNotes/ReadingNotes.html">
            
                    
                    ReadingNotes
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.1" data-path="../../ReadingNotes/éå¹´å¨éæ©èä¸æ¶çèè-é©¬åæ-1835.html">
            
                <a href="../../ReadingNotes/éå¹´å¨éæ©èä¸æ¶çèè-é©¬åæ-1835.html">
            
                    
                    éå¹´å¨éæ©èä¸æ¶çèè-é©¬åæ
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2" data-path="../../ReadingNotes/ç ç©¶ä¸å­¦é£-å¼ ç³åº-1948.html">
            
                <a href="../../ReadingNotes/ç ç©¶ä¸å­¦é£-å¼ ç³åº-1948.html">
            
                    
                    ç ç©¶ä¸å­¦é£-å¼ ç³åº-1948
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.3" data-path="../../ReadingNotes/è®ºéå¹´ä¿®å»-å¼ ç³åº-1946.html">
            
                <a href="../../ReadingNotes/è®ºéå¹´ä¿®å»-å¼ ç³åº-1946.html">
            
                    
                    è®ºéå¹´ä¿®å»-å¼ ç³åº-1946
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.4" data-path="../../ReadingNotes/è®ºéå¹´çä¿®å»-å¼ é»å¤©-1938.html">
            
                <a href="../../ReadingNotes/è®ºéå¹´çä¿®å»-å¼ é»å¤©-1938.html">
            
                    
                    è®ºéå¹´çä¿®å»-å¼ é»å¤©-1938
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.5" data-path="../../ReadingNotes/è®¡ç®ä¹é­-å´å/">
            
                <a href="../../ReadingNotes/è®¡ç®ä¹é­-å´å/">
            
                    
                    è®¡ç®ä¹é­
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.6" data-path="../../ReadingNotes/è¯­å½-æ¯æ³½ä¸.html">
            
                <a href="../../ReadingNotes/è¯­å½-æ¯æ³½ä¸.html">
            
                    
                    Mao
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >Learn CUDA</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="cuda-learn">CUDA Learn</h1>
<ul>
<li><a href="https://docs.nvidia.com/cuda/doc/index.html" target="_blank">NVIDIA CUDA documentation</a></li>
<li><a href="https://developer.nvidia.com/cuda-education" target="_blank">NVIDIA cuda-education</a></li>
<li><a href="https://github.com/houhuawei23/cuda-samples" target="_blank">cuda-samples</a></li>
<li><a href="https://www.youtube.com/watch?v=86FAWCzIe_4&amp;t=13s" target="_blank">CUDA Programming Course &#x2013; High-Performance Computing with GPUs</a></li>
<li><a href="https://www.reddit.com/r/MachineLearning/comments/w52iev/d_what_are_some_good_resources_to_learn_cuda/?rdt=40526" target="_blank">d_what_are_some_good_resources_to_learn_cuda</a></li>
<li><a href="https://www.quora.com/What-are-some-of-the-best-resources-to-learn-CUDA-C" target="_blank">What-are-some-of-the-best-resources-to-learn-CUDA-C</a></li>
<li><a href="https://www.olcf.ornl.gov/cuda-training-series/" target="_blank">cuda-training-series</a></li>
<li><a href="https://developer.nvidia.com/blog/even-easier-introduction-cuda/" target="_blank">even-easier-introduction-cuda</a></li>
<li><a href="https://learnopencv.com/demystifying-gpu-architectures-for-deep-learning/" target="_blank">demystifying-gpu-architectures-for-deep-learning</a></li>
<li><a href="https://numba.readthedocs.io/en/stable/cuda/overview.html" target="_blank">numba</a></li>
<li><a href="https://github.com/houhuawei23/GPU-Puzzles" target="_blank">GPU-Puzzles</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/34587739" target="_blank">CUDA &#x7F16;&#x7A0B;&#x5165;&#x95E8;&#x6781;&#x7B80;&#x6559;&#x7A0B;</a></li>
<li><a href="https://lulaoshi.info/gpu/" target="_blank">GPU &#x7F16;&#x7A0B;</a></li>
<li><a href="https://docs.nvidia.com/cuda/nvvm-ir-spec/" target="_blank">nvvm-ir-spec</a></li>
</ul>
<h2 id="nvidia-cuda-compute-unified-device-architecture">NVIDIA CUDA (Compute Unified Device Architecture)</h2>
<p>The NVIDIA&#xAE; CUDA&#xAE; Toolkit provides a comprehensive development environment for C and C++ developers building GPU-accelerated applications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers. The toolkit includes GPU-accelerated libraries, debugging and optimization tools, a C/C++ compiler, and a runtime library to deploy your application.</p>
<p>NVIDIA&#xAE; CUDA&#xAE; &#x5DE5;&#x5177;&#x5305;&#x4E3A;&#x6784;&#x5EFA; GPU &#x52A0;&#x901F;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x7684; C &#x548C; C++ &#x5F00;&#x53D1;&#x4EBA;&#x5458;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x4E2A;&#x5168;&#x9762;&#x7684;&#x5F00;&#x53D1;&#x73AF;&#x5883;&#x3002;&#x501F;&#x52A9; CUDA &#x5DE5;&#x5177;&#x5305;&#xFF0C;&#x60A8;&#x53EF;&#x4EE5;&#x5728; GPU &#x52A0;&#x901F;&#x7684;&#x5D4C;&#x5165;&#x5F0F;&#x7CFB;&#x7EDF;&#x3001;&#x684C;&#x9762;&#x5DE5;&#x4F5C;&#x7AD9;&#x3001;&#x4F01;&#x4E1A;&#x6570;&#x636E;&#x4E2D;&#x5FC3;&#x3001;&#x57FA;&#x4E8E;&#x4E91;&#x7684;&#x5E73;&#x53F0;&#x548C; HPC &#x8D85;&#x7EA7;&#x8BA1;&#x7B97;&#x673A;&#x4E0A;&#x5F00;&#x53D1;&#x3001;&#x4F18;&#x5316;&#x548C;&#x90E8;&#x7F72;&#x60A8;&#x7684;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x3002;&#x8BE5;&#x5DE5;&#x5177;&#x5305;&#x5305;&#x62EC; GPU &#x52A0;&#x901F;&#x5E93;&#x3001;&#x8C03;&#x8BD5;&#x548C;&#x4F18;&#x5316;&#x5DE5;&#x5177;&#x3001;C/C++ &#x7F16;&#x8BD1;&#x5668;&#x4EE5;&#x53CA;&#x7528;&#x4E8E;&#x90E8;&#x7F72;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x7684;&#x8FD0;&#x884C;&#x65F6;&#x5E93;&#x3002;</p>
<p>Using built-in capabilities for distributing computations across multi-GPU configurations, scientists and researchers can develop applications that scale from single GPU workstations to cloud installations with thousands of GPUs.</p>
<p>&#x4F7F;&#x7528;&#x5185;&#x7F6E;&#x529F;&#x80FD;&#x5728;&#x591A; GPU &#x914D;&#x7F6E;&#x4E4B;&#x95F4;&#x5206;&#x914D;&#x8BA1;&#x7B97;&#xFF0C;&#x79D1;&#x5B66;&#x5BB6;&#x548C;&#x7814;&#x7A76;&#x4EBA;&#x5458;&#x53EF;&#x4EE5;&#x5F00;&#x53D1;&#x4ECE;&#x5355;&#x4E2A; GPU &#x5DE5;&#x4F5C;&#x7AD9;&#x6269;&#x5C55;&#x5230;&#x5177;&#x6709;&#x6570;&#x5343;&#x4E2A; GPU &#x7684;&#x4E91;&#x5B89;&#x88C5;&#x7684;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x3002;</p>
<h3 id="cuda-c-programming-guide-v126">CUDA C++ Programming Guide v12.6</h3>
<p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/" target="_blank">CUDA C++ Programming Guide</a></p>
<p>CUDA &#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x7684;&#x5173;&#x952E;&#x7EC4;&#x6210;&#x90E8;&#x5206; (GPT)</p>
<p>CUDA &#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x4F7F;&#x5F00;&#x53D1;&#x8005;&#x80FD;&#x591F;&#x7F16;&#x5199;&#x4EE3;&#x7801;&#xFF0C;&#x5145;&#x5206;&#x5229;&#x7528; NVIDIA GPU &#x7684;&#x5F3A;&#x5927;&#x5E76;&#x884C;&#x8BA1;&#x7B97;&#x80FD;&#x529B;&#x3002;&#x5B83;&#x57FA;&#x4E8E;&#x5355;&#x6307;&#x4EE4;&#x591A;&#x7EBF;&#x7A0B;&#xFF08;SIMT&#xFF09;&#x67B6;&#x6784;&#xFF0C;&#x5176;&#x4E2D;&#x591A;&#x4E2A;&#x7EBF;&#x7A0B;&#x540C;&#x65F6;&#x6267;&#x884C;&#x76F8;&#x540C;&#x7684;&#x6307;&#x4EE4;&#xFF0C;&#x4F46;&#x5904;&#x7406;&#x4E0D;&#x540C;&#x7684;&#x6570;&#x636E;&#x3002;CUDA &#x901A;&#x8FC7;&#x5206;&#x5C42;&#x7684;&#x7EBF;&#x7A0B;&#x7ED3;&#x6784;&#x548C;&#x5185;&#x5B58;&#x7BA1;&#x7406;&#x7CFB;&#x7EDF;&#xFF0C;&#x9AD8;&#x6548;&#x7EC4;&#x7EC7;&#x8BA1;&#x7B97;&#x4EFB;&#x52A1;&#x3002;</p>
<ol>
<li><p>&#x7EBF;&#x7A0B;&#x5C42;&#x6B21;&#x7ED3;&#x6784;&#xFF1A;</p>
<ul>
<li>&#x7EBF;&#x7A0B;&#xFF08;Thread&#xFF09;&#xFF1A;&#x6267;&#x884C;&#x7279;&#x5B9A;&#x4EFB;&#x52A1;&#x7684;&#x6700;&#x5C0F;&#x6267;&#x884C;&#x5355;&#x5143;&#x3002;</li>
<li>&#x7EBF;&#x7A0B;&#x5757;&#xFF08;Thread Block&#xFF09;&#xFF1A;&#x7EBF;&#x7A0B;&#x7684;&#x96C6;&#x5408;&#xFF0C;&#x7EBF;&#x7A0B;&#x5757;&#x4E2D;&#x7684;&#x7EBF;&#x7A0B;&#x5171;&#x540C;&#x6267;&#x884C;&#x4EFB;&#x52A1;&#x3002;&#x4E00;&#x4E2A;&#x7EBF;&#x7A0B;&#x5757;&#x6700;&#x591A;&#x5305;&#x542B; 1024 &#x4E2A;&#x7EBF;&#x7A0B;&#xFF08;&#x5177;&#x4F53;&#x53D6;&#x51B3;&#x4E8E; GPU &#x67B6;&#x6784;&#xFF09;&#x3002;</li>
<li>&#x7F51;&#x683C;&#xFF08;Grid&#xFF09;&#xFF1A;&#x7EBF;&#x7A0B;&#x5757;&#x7684;&#x96C6;&#x5408;&#x3002;&#x7F51;&#x683C;&#x53EF;&#x4EE5;&#x662F; 1D&#x3001;2D &#x6216; 3D&#xFF0C;&#x4EE5;&#x4FBF;&#x66F4;&#x65B9;&#x4FBF;&#x5730;&#x5C06;&#x7EBF;&#x7A0B;&#x6620;&#x5C04;&#x5230;&#x6570;&#x636E;&#x4E0A;&#x3002;</li>
</ul>
<p>&#x901A;&#x8FC7;&#x552F;&#x4E00;&#x7684;&#x7D22;&#x5F15;&#xFF08;&#x5982; <code>threadIdx</code>&#x3001;<code>blockIdx</code>&#x3001;<code>blockDim</code> &#x548C; <code>gridDim</code>&#xFF09;&#xFF0C;&#x6BCF;&#x4E2A;&#x7EBF;&#x7A0B;&#x53EF;&#x4EE5;&#x8BBF;&#x95EE;&#x7279;&#x5B9A;&#x7684;&#x6570;&#x636E;&#x90E8;&#x5206;&#x3002;</p>
</li>
<li><p>&#x5185;&#x5B58;&#x5C42;&#x6B21;&#x7ED3;&#x6784;&#xFF1A;</p>
<ul>
<li>&#x5168;&#x5C40;&#x5185;&#x5B58;&#xFF08;Global Memory&#xFF09;&#xFF1A;&#x6240;&#x6709;&#x7EBF;&#x7A0B;&#x90FD;&#x53EF;&#x4EE5;&#x8BBF;&#x95EE;&#xFF0C;&#x4F46;&#x8BBF;&#x95EE;&#x5EF6;&#x8FDF;&#x8F83;&#x9AD8;&#x3002;</li>
<li>&#x5171;&#x4EAB;&#x5185;&#x5B58;&#xFF08;Shared Memory&#xFF09;&#xFF1A;&#x7EBF;&#x7A0B;&#x5757;&#x5185;&#x7684;&#x7EBF;&#x7A0B;&#x5171;&#x4EAB;&#x7684;&#x4E00;&#x79CD;&#x5FEB;&#x901F;&#x3001;&#x4F4E;&#x5EF6;&#x8FDF;&#x7684;&#x5185;&#x5B58;&#x3002;</li>
<li>&#x5C40;&#x90E8;&#x5185;&#x5B58;&#xFF08;Local Memory&#xFF09;&#xFF1A;&#x6BCF;&#x4E2A;&#x7EBF;&#x7A0B;&#x7684;&#x79C1;&#x6709;&#x5185;&#x5B58;&#xFF0C;&#x4F46;&#x7531;&#x4E8E;&#x4F4D;&#x4E8E;&#x5168;&#x5C40;&#x5185;&#x5B58;&#x4E2D;&#xFF0C;&#x8BBF;&#x95EE;&#x901F;&#x5EA6;&#x8F83;&#x6162;&#x3002;</li>
<li>&#x5BC4;&#x5B58;&#x5668;&#xFF08;Registers&#xFF09;&#xFF1A;&#x901F;&#x5EA6;&#x6781;&#x5FEB;&#xFF0C;&#x4F46;&#x6570;&#x91CF;&#x6709;&#x9650;&#xFF0C;&#x7528;&#x4E8E;&#x5B58;&#x50A8;&#x7EBF;&#x7A0B;&#x7684;&#x4E34;&#x65F6;&#x53D8;&#x91CF;&#x3002;</li>
</ul>
</li>
<li><p>&#x5185;&#x6838;&#xFF08;Kernel&#xFF09;&#xFF1A;</p>
<ul>
<li>CUDA &#x5185;&#x6838;&#x662F;&#x8FD0;&#x884C;&#x5728; GPU &#x4E0A;&#x7684;&#x51FD;&#x6570;&#xFF0C;&#x4F7F;&#x7528; C/C++ &#x8BED;&#x8A00;&#x7F16;&#x5199;&#x5E76;&#x5E26;&#x6709;&#x7279;&#x6B8A;&#x7684;&#x8BED;&#x6CD5;&#x6807;&#x8BB0;&#x3002;&#x5185;&#x6838;&#x4ECE; CPU &#x53D1;&#x8D77;&#xFF0C;&#x5E76;&#x7531; GPU &#x7684;&#x7EBF;&#x7A0B;&#x5E76;&#x884C;&#x6267;&#x884C;&#x3002;</li>
</ul>
</li>
</ol>
<h4 id="introduction">Introduction</h4>
<p>The advent of multicore CPUs and manycore GPUs means that mainstream processor chips are now parallel systems.</p>
<p>The challenge is to develop application software that transparently scales its parallelism to leverage the increasing number of processor cores.</p>
<p>The CUDA parallel programming model is designed to overcome this challenge while maintaing a low learning curve for programmers familiar with C.</p>
<p>Its core is three key abstractions:</p>
<ul>
<li>a hierarchy of thread groups: &#x5C42;&#x7EA7;&#x7EBF;&#x7A0B;&#x7EC4;</li>
<li>shared memories: &#x5171;&#x4EAB;&#x5185;&#x5B58;</li>
<li>barrier synchronization: &#x969C;&#x788D;&#x540C;&#x6B65;</li>
</ul>
<p>These abstractions provide fine-grained data parallelism and thread parallelism, nested within coarse-grained data parallelism and task parallelism. They guide the programmer to partition the problem into coarse sub-problems that can be solved independently in parallel by blocks of threads, and each sub-problem into finer pieces that can be solved cooperatively in parallel by all threads within the block.</p>
<p>&#x8FD9;&#x4E9B;&#x62BD;&#x8C61;&#x63D0;&#x4F9B;&#x4E86;&#x7EC6;&#x7C92;&#x5EA6;&#x6570;&#x636E;&#x5E76;&#x884C;&#x6027;&#x548C;&#x7EBF;&#x7A0B;&#x5E76;&#x884C;&#x6027;&#xFF0C;&#x5D4C;&#x5957;&#x5728;&#x7C97;&#x7C92;&#x5EA6;&#x6570;&#x636E;&#x5E76;&#x884C;&#x6027;&#x548C;&#x4EFB;&#x52A1;&#x5E76;&#x884C;&#x6027;&#x4E2D;&#x3002;&#x5B83;&#x4EEC;&#x5F15;&#x5BFC;&#x7A0B;&#x5E8F;&#x5458;&#x5C06;&#x95EE;&#x9898;&#x5212;&#x5206;&#x4E3A;&#x53EF;&#x4EE5;&#x7531;&#x7EBF;&#x7A0B;&#x5757;&#x72EC;&#x7ACB;&#x5E76;&#x884C;&#x89E3;&#x51B3;&#x7684;&#x7C97;&#x7565;&#x5B50;&#x95EE;&#x9898;&#xFF0C;&#x5E76;&#x5C06;&#x6BCF;&#x4E2A;&#x5B50;&#x95EE;&#x9898;&#x5212;&#x5206;&#x4E3A;&#x53EF;&#x4EE5;&#x7531;&#x5757;&#x5185;&#x7684;&#x6240;&#x6709;&#x7EBF;&#x7A0B;&#x5E76;&#x884C;&#x534F;&#x4F5C;&#x89E3;&#x51B3;&#x7684;&#x66F4;&#x7CBE;&#x7EC6;&#x7684;&#x90E8;&#x5206;&#x3002;</p>
<p>This decomposition preserves language expressivity by allowing threads to cooperate when solving each sub-problem, and at the same time enables automatic scalability. Indeed, each block of threads can be scheduled on any of the available multiprocessors within a GPU, in any order, concurrently or sequentially, so that a compiled CUDA program can execute on any number of multiprocessors as illustrated by Figure 3, and only the runtime system needs to know the physical multiprocessor count.</p>
<p>&#x8FD9;&#x79CD;&#x5206;&#x89E3;&#x901A;&#x8FC7;&#x5141;&#x8BB8;&#x7EBF;&#x7A0B;&#x5728;&#x89E3;&#x51B3;&#x6BCF;&#x4E2A;&#x5B50;&#x95EE;&#x9898;&#x65F6;&#x8FDB;&#x884C;&#x5408;&#x4F5C;&#x6765;&#x4FDD;&#x7559;&#x8BED;&#x8A00;&#x8868;&#x8FBE;&#x80FD;&#x529B;&#xFF0C;&#x540C;&#x65F6;&#x5B9E;&#x73B0;&#x81EA;&#x52A8;&#x53EF;&#x6269;&#x5C55;&#x6027;&#x3002;&#x4E8B;&#x5B9E;&#x4E0A;&#xFF0C;&#x6BCF;&#x4E2A;&#x7EBF;&#x7A0B;&#x5757;&#x90FD;&#x53EF;&#x4EE5;&#x4EE5;&#x4EFB;&#x4F55;&#x987A;&#x5E8F;&#xFF08;&#x540C;&#x65F6;&#x6216;&#x987A;&#x5E8F;&#xFF09;&#x8C03;&#x5EA6;&#x5230; GPU &#x5185;&#x7684;&#x4EFB;&#x4F55;&#x53EF;&#x7528;&#x591A;&#x5904;&#x7406;&#x5668;&#x4E0A;&#xFF0C;&#x4EE5;&#x4FBF;&#x7F16;&#x8BD1;&#x540E;&#x7684; CUDA &#x7A0B;&#x5E8F;&#x53EF;&#x4EE5;&#x5728;&#x4EFB;&#x610F;&#x6570;&#x91CF;&#x7684;&#x591A;&#x5904;&#x7406;&#x5668;&#x4E0A;&#x6267;&#x884C;&#xFF0C;&#x5982;&#x56FE; 3 &#x6240;&#x793A;&#xFF0C;&#x5E76;&#x4E14;&#x4EC5;&#x8FD0;&#x884C;&#x65F6;&#x7CFB;&#x7EDF;&#x9700;&#x8981;&#x77E5;&#x9053;&#x7269;&#x7406;&#x591A;&#x5904;&#x7406;&#x5668;&#x6570;&#x91CF;&#x3002;</p>
<p align="center">
 <img src="automatic-scalability.png" alt="automatic-scalability" title="automatic-scalability" style="zoom:70%;">
</p>

<p>A GPU is built around an array of Streaming Multiprocessors (SMs)</p>
<p>GPU &#x7531;&#x6D41;&#x5F0F;&#x591A;&#x5904;&#x7406;&#x5668; (SM) &#x9635;&#x5217;&#x6784;&#x5EFA;</p>
<h4 id="programming-model-&#x7F16;&#x7A0B;&#x6A21;&#x578B;">Programming Model &#x7F16;&#x7A0B;&#x6A21;&#x578B;</h4>
<ul>
<li>Kernels: &#x5185;&#x6838;&#x51FD;&#x6570;</li>
<li>Thread Hierarachy: &#x7EBF;&#x7A0B;&#x5C42;&#x6B21;&#x7ED3;&#x6784;</li>
<li>Memory Hierarachy: &#x5185;&#x5B58;&#x5C42;&#x6B21;&#x7ED3;&#x6784;</li>
<li>Heteroheneous Programming: &#x5F02;&#x6784;&#x7F16;&#x7A0B;</li>
<li>Asynchronous SIMT Programming Model: &#x5F02;&#x6B65; SIMT &#x7F16;&#x7A0B;&#x6A21;&#x578B;</li>
<li>Compute Capability: &#x8BA1;&#x7B97;&#x80FD;&#x529B;</li>
</ul>
<h5 id="kernels-&#x5185;&#x6838;&#x51FD;&#x6570;">Kernels: &#x5185;&#x6838;&#x51FD;&#x6570;</h5>
<p>CUDA C++ extends C++ by allowing the programmer to define C++ functions, called kernels, that, when called, are executed N times in parallel by N different CUDA threads, as opposed to only once like regular C++ functions.</p>
<p>CUDA C++ &#x901A;&#x8FC7;&#x5141;&#x8BB8;&#x7A0B;&#x5E8F;&#x5458;&#x5B9A;&#x4E49;&#x79F0;&#x4E3A;&#x5185;&#x6838;&#x7684; C++ &#x51FD;&#x6570;&#x6765;&#x6269;&#x5C55; C++&#xFF0C;&#x8FD9;&#x4E9B;&#x51FD;&#x6570;&#x5728;&#x8C03;&#x7528;&#x65F6;&#x7531; N &#x4E2A;&#x4E0D;&#x540C;&#x7684; CUDA &#x7EBF;&#x7A0B;&#x5E76;&#x884C;&#x6267;&#x884C; N &#x6B21;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x50CF;&#x5E38;&#x89C4; C++ &#x51FD;&#x6570;&#x90A3;&#x6837;&#x53EA;&#x80FD;&#x6267;&#x884C;&#x4E00;&#x6B21;&#x3002;</p>
<p>A kernel is defined using the <code>__global__</code> declaration specifier and the number of CUDA threads that execute that kernel for a given kernel call is specified using a new <code>&lt;&lt;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>...</span><span class="token punctuation">&gt;</span></span>&gt;&gt;</code> execution configuration syntax (see C++ Language Extensions). Each thread that executes the kernel is given a unique <code>thread ID</code> that is accessible within the kernel through built-in variables.</p>
<p>&#x4F7F;&#x7528; <code>__global__</code> &#x58F0;&#x660E;&#x8BF4;&#x660E;&#x7B26;&#x5B9A;&#x4E49;&#x5185;&#x6838;&#xFF0C;&#x5E76;&#x4F7F;&#x7528;&#x65B0;&#x7684; <code>&lt;&lt;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>...</span><span class="token punctuation">&gt;</span></span>&gt;&gt;</code> &#x6267;&#x884C;&#x914D;&#x7F6E;&#x8BED;&#x6CD5;&#x6307;&#x5B9A;&#x4E3A;&#x7ED9;&#x5B9A;&#x5185;&#x6838;&#x8C03;&#x7528;&#x6267;&#x884C;&#x8BE5;&#x5185;&#x6838;&#x7684; CUDA &#x7EBF;&#x7A0B;&#x6570;&#xFF08;&#x8BF7;&#x53C2;&#x9605; C++&#x8BED;&#x8A00;&#x6269;&#x5C55;&#xFF09;&#x3002;&#x6BCF;&#x4E2A;&#x6267;&#x884C;&#x5185;&#x6838;&#x7684;&#x7EBF;&#x7A0B;&#x90FD;&#x4F1A;&#x88AB;&#x8D4B;&#x4E88;&#x4E00;&#x4E2A;&#x552F;&#x4E00;&#x7684;&#x7EBF;&#x7A0B; ID &#xFF0C;&#x8BE5; ID &#x53EF;&#x4EE5;&#x5728;&#x5185;&#x6838;&#x4E2D;&#x901A;&#x8FC7;&#x5185;&#x7F6E;&#x53D8;&#x91CF;&#x8FDB;&#x884C;&#x8BBF;&#x95EE;&#x3002;</p>
<h5 id="thread-hierarachy-&#x7EBF;&#x7A0B;&#x5C42;&#x6B21;&#x7ED3;&#x6784;">Thread Hierarachy: &#x7EBF;&#x7A0B;&#x5C42;&#x6B21;&#x7ED3;&#x6784;</h5>
<ul>
<li>grids - blocks - threads</li>
<li>&#x5757;&#x5185;&#x7EBF;&#x7A0B;&#x9A7B;&#x7559;&#x5728;&#x540C;&#x4E00;&#x4E2A; core &#x4E0A;&#xFF0C;&#x5171;&#x4EAB;&#x5185;&#x5B58;</li>
<li>blocks, threads &#x7531;&#x4E09;&#x7EF4;&#x4E0B;&#x6807;&#x7D22;&#x5F15;<ul>
<li>threadIdx.x, .y, .z</li>
<li>blockIdx.x, .y, .z</li>
</ul>
</li>
<li>block &#x5C3A;&#x5BF8;:<ul>
<li>blockDim.x, .y, .z</li>
</ul>
</li>
</ul>
<p>For convenience, threadIdx is a 3-component vector, so that threads can be identified using a one-dimensional, two-dimensional, or three-dimensional thread index, forming a one-dimensional, two-dimensional, or three-dimensional block of threads, called a thread block. This provides a natural way to invoke computation across the elements in a domain such as a vector, matrix, or volume.</p>
<p>The index of a thread and its thread ID relate to each other in a straightforward way:</p>
<ul>
<li>For a one-dimensional block, they are the same;</li>
<li>for a two-dimensional block of size <code>(Dx, Dy)</code>, the thread ID of a thread of index <code>(x, y)</code> is <code>(x + y Dx)</code>;</li>
<li>for a three-dimensional block of size <code>(Dx, Dy, Dz)</code>, the thread ID of a thread of index <code>(x, y, z)</code> is <code>(x + y Dx + z Dx Dy)</code>.</li>
</ul>
<p>There is a limit to the number of threads per block, since all threads of a block are expected to reside on the same streaming multiprocessor core and must share the limited memory resources of that core. On current GPUs, a thread block may contain up to 1024 threads.</p>
<p>&#x6BCF;&#x4E2A;&#x5757;&#x7684;&#x7EBF;&#x7A0B;&#x6570;&#x91CF;&#x662F;&#x6709;&#x9650;&#x7684;&#xFF0C;&#x56E0;&#x4E3A;&#x5757;&#x7684;&#x6240;&#x6709;&#x7EBF;&#x7A0B;&#x90FD;&#x5E94;&#x8BE5;&#x9A7B;&#x7559;&#x5728;&#x540C;&#x4E00;&#x4E2A;&#x6D41;&#x5F0F;&#x591A;&#x5904;&#x7406;&#x5668;&#x6838;&#x5FC3;&#x4E0A;&#xFF0C;&#x5E76;&#x4E14;&#x5FC5;&#x987B;&#x5171;&#x4EAB;&#x8BE5;&#x6838;&#x5FC3;&#x7684;&#x6709;&#x9650;&#x5185;&#x5B58;&#x8D44;&#x6E90;&#x3002;&#x5728;&#x5F53;&#x524D;&#x7684; GPU &#x4E0A;&#xFF0C;&#x4E00;&#x4E2A;&#x7EBF;&#x7A0B;&#x5757;&#x6700;&#x591A;&#x53EF;&#x4EE5;&#x5305;&#x542B; 1024 &#x4E2A;&#x7EBF;&#x7A0B;&#x3002;</p>
<p>However, a kernel can be executed by multiple equally-shaped thread blocks, so that the total number of threads is equal to the number of threads per block times the number of blocks.</p>
<p>&#x7136;&#x800C;&#xFF0C;&#x4E00;&#x4E2A;&#x5185;&#x6838;&#x53EF;&#x4EE5;&#x7531;&#x591A;&#x4E2A;&#x5F62;&#x72B6;&#x76F8;&#x540C;&#x7684;&#x7EBF;&#x7A0B;&#x5757;&#x6765;&#x6267;&#x884C;&#xFF0C;&#x56E0;&#x6B64;&#x7EBF;&#x7A0B;&#x603B;&#x6570;&#x7B49;&#x4E8E;&#x6BCF;&#x4E2A;&#x5757;&#x7684;&#x7EBF;&#x7A0B;&#x6570;&#x4E58;&#x4EE5;&#x5757;&#x6570;&#x3002;</p>
<p>Blocks are organized into a one-dimensional, two-dimensional, or three-dimensional grid of thread blocks as illustrated by Figure 4. The number of thread blocks in a grid is usually dictated by the size of the data being processed, which typically exceeds the number of processors in the system.</p>
<p>&#x5757;&#x88AB;&#x7EC4;&#x7EC7;&#x6210;&#x4E00;&#x7EF4;&#x3001;&#x4E8C;&#x7EF4;&#x6216;&#x4E09;&#x7EF4;&#x7EBF;&#x7A0B;&#x5757;&#x7F51;&#x683C;&#xFF0C;&#x5982;&#x56FE; 4 &#x6240;&#x793A;&#x3002;&#x7F51;&#x683C;&#x4E2D;&#x7EBF;&#x7A0B;&#x5757;&#x7684;&#x6570;&#x91CF;&#x901A;&#x5E38;&#x7531;&#x6B63;&#x5728;&#x5904;&#x7406;&#x7684;&#x6570;&#x636E;&#x5927;&#x5C0F;&#x51B3;&#x5B9A;&#xFF0C;&#x8BE5;&#x6570;&#x636E;&#x901A;&#x5E38;&#x8D85;&#x8FC7;&#x7CFB;&#x7EDF;&#x4E2D;&#x5904;&#x7406;&#x5668;&#x7684;&#x6570;&#x91CF;&#x3002;</p>
<p>Extending the previous MatAdd() example to handle multiple blocks, the code becomes as follows.</p>
<pre class="language-"><code class="lang-c++">// Kernel definition
__global__ void MatAdd(float A[N][N], float B[N][N],
float C[N][N]) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    if (i &lt; N &amp;&amp; j &lt; N)
        C[i][j] = A[i][j] + B[i][j];
}

int main() {
    ...
    // Kernel invocation
    dim3 threadsPerBlock(16, 16);
    dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);
    MatAdd&lt;&lt;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>numBlocks,</span> <span class="token attr-name">threadsPerBlock</span><span class="token punctuation">&gt;</span></span>&gt;&gt;(A, B, C);
    ...
}
</code></pre>
<p>Threads within a block can cooperate by sharing data through some <code>shared memory</code> and by <code>synchronizing</code> their execution to coordinate memory accesses. More precisely, one can specify synchronization points in the kernel by calling the <code>__syncthreads()</code> intrinsic function;</p>
<p><code>__syncthreads()</code> acts as a <code>barrier</code> at which all threads in the block must wait before any is allowed to proceed. In addition to <code>__syncthreads()</code>, the Cooperative Groups API provides a rich set of thread-synchronization primitives.</p>
<p>&#x5757;&#x5185;&#x7684;&#x7EBF;&#x7A0B;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x67D0;&#x4E9B;&#x5171;&#x4EAB;&#x5185;&#x5B58;&#x5171;&#x4EAB;&#x6570;&#x636E;&#x5E76;&#x540C;&#x6B65;&#x5176;&#x6267;&#x884C;&#x6765;&#x534F;&#x8C03;&#x5185;&#x5B58;&#x8BBF;&#x95EE;&#x6765;&#x8FDB;&#x884C;&#x534F;&#x4F5C;&#x3002;&#x66F4;&#x51C6;&#x786E;&#x5730;&#x8BF4;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x8C03;&#x7528;<code>__syncthreads()</code>&#x5185;&#x90E8;&#x51FD;&#x6570;&#x6765;&#x6307;&#x5B9A;&#x5185;&#x6838;&#x4E2D;&#x7684;&#x540C;&#x6B65;&#x70B9;&#xFF1B;</p>
<p><code>__syncthreads()</code>&#x5145;&#x5F53;&#x5C4F;&#x969C;&#xFF0C;&#x5757;&#x4E2D;&#x7684;&#x6240;&#x6709;&#x7EBF;&#x7A0B;&#x90FD;&#x5FC5;&#x987B;&#x7B49;&#x5F85;&#xFF0C;&#x7136;&#x540E;&#x624D;&#x5141;&#x8BB8;&#x4EFB;&#x4F55;&#x7EBF;&#x7A0B;&#x7EE7;&#x7EED;&#x8FDB;&#x884C;&#x3002;&#x9664;&#x4E86;<code>__syncthreads()</code>&#x4E4B;&#x5916;&#xFF0C;&#x534F;&#x4F5C;&#x7EC4; API &#x8FD8;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x7EC4;&#x4E30;&#x5BCC;&#x7684;&#x7EBF;&#x7A0B;&#x540C;&#x6B65;&#x539F;&#x8BED;&#x3002;</p>
<p>For efficient cooperation, the shared memory is expected to be a low-latency memory near each processor core (much like an L1 cache) and <code>__syncthreads()</code> is expected to be lightweight.</p>
<p>&#x4E3A;&#x4E86;&#x9AD8;&#x6548;&#x5408;&#x4F5C;&#xFF0C;&#x5171;&#x4EAB;&#x5185;&#x5B58;&#x5E94;&#x8BE5;&#x662F;&#x6BCF;&#x4E2A;&#x5904;&#x7406;&#x5668;&#x6838;&#x5FC3;&#x9644;&#x8FD1;&#x7684;&#x4F4E;&#x5EF6;&#x8FDF;&#x5185;&#x5B58;&#xFF08;&#x5F88;&#x50CF; L1 &#x7F13;&#x5B58;&#xFF09;&#xFF0C;&#x5E76;&#x4E14;<code>__syncthreads()</code>&#x5E94;&#x8BE5;&#x662F;&#x8F7B;&#x91CF;&#x7EA7;&#x7684;&#x3002;</p>
<h5 id="memory-hierarachy-&#x5185;&#x5B58;&#x5C42;&#x6B21;&#x7ED3;&#x6784;">Memory Hierarachy: &#x5185;&#x5B58;&#x5C42;&#x6B21;&#x7ED3;&#x6784;</h5>
<p>CUDA threads may access data from multiple memory spaces during their execution as illustrated by Figure 6. Each thread has private local memory. Each thread block has shared memory visible to all threads of the block and with the same lifetime as the block. Thread blocks in a thread block cluster can perform read, write, and atomics operations on each other&#x2019;s shared memory. All threads have access to the same global memory.</p>
<p>CUDA &#x7EBF;&#x7A0B;&#x5728;&#x6267;&#x884C;&#x671F;&#x95F4;&#x53EF;&#x4EE5;&#x8BBF;&#x95EE;&#x591A;&#x4E2A;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x4E2D;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x5982;&#x56FE; 6 &#x6240;&#x793A;&#x3002;&#x6BCF;&#x4E2A;&#x7EBF;&#x7A0B;&#x90FD;&#x6709;&#x79C1;&#x6709;&#x672C;&#x5730;&#x5185;&#x5B58;&#x3002;&#x6BCF;&#x4E2A;&#x7EBF;&#x7A0B;&#x5757;&#x90FD;&#x6709;&#x5BF9;&#x8BE5;&#x5757;&#x7684;&#x6240;&#x6709;&#x7EBF;&#x7A0B;&#x53EF;&#x89C1;&#x7684;&#x5171;&#x4EAB;&#x5185;&#x5B58;&#xFF0C;&#x5E76;&#x4E14;&#x4E0E;&#x8BE5;&#x5757;&#x5177;&#x6709;&#x76F8;&#x540C;&#x7684;&#x751F;&#x547D;&#x5468;&#x671F;&#x3002;&#x7EBF;&#x7A0B;&#x5757;&#x7C07;&#x4E2D;&#x7684;&#x7EBF;&#x7A0B;&#x5757;&#x53EF;&#x4EE5;&#x5BF9;&#x5F7C;&#x6B64;&#x7684;&#x5171;&#x4EAB;&#x5185;&#x5B58;&#x6267;&#x884C;&#x8BFB;&#x3001;&#x5199;&#x548C;&#x539F;&#x5B50;&#x64CD;&#x4F5C;&#x3002;&#x6240;&#x6709;&#x7EBF;&#x7A0B;&#x90FD;&#x53EF;&#x4EE5;&#x8BBF;&#x95EE;&#x76F8;&#x540C;&#x7684;&#x5168;&#x5C40;&#x5185;&#x5B58;&#x3002;</p>
<p>There are also two additional read-only memory spaces accessible by all threads: the constant and texture memory spaces. The global, constant, and texture memory spaces are optimized for different memory usages (see Device Memory Accesses). Texture memory also offers different addressing modes, as well as data filtering, for some specific data formats (see Texture and Surface Memory).</p>
<p>&#x8FD8;&#x6709;&#x4E24;&#x4E2A;&#x53EF;&#x4F9B;&#x6240;&#x6709;&#x7EBF;&#x7A0B;&#x8BBF;&#x95EE;&#x7684;&#x9644;&#x52A0;&#x53EA;&#x8BFB;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#xFF1A;&#x5E38;&#x91CF;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x548C;&#x7EB9;&#x7406;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x3002;&#x5168;&#x5C40;&#x3001;&#x5E38;&#x91CF;&#x548C;&#x7EB9;&#x7406;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x9488;&#x5BF9;&#x4E0D;&#x540C;&#x7684;&#x5185;&#x5B58;&#x4F7F;&#x7528;&#x8FDB;&#x884C;&#x4E86;&#x4F18;&#x5316;&#xFF08;&#x8BF7;&#x53C2;&#x9605;&#x8BBE;&#x5907;&#x5185;&#x5B58;&#x8BBF;&#x95EE;&#xFF09;&#x3002;&#x7EB9;&#x7406;&#x5185;&#x5B58;&#x8FD8;&#x4E3A;&#x67D0;&#x4E9B;&#x7279;&#x5B9A;&#x7684;&#x6570;&#x636E;&#x683C;&#x5F0F;&#x63D0;&#x4F9B;&#x4E0D;&#x540C;&#x7684;&#x5BFB;&#x5740;&#x6A21;&#x5F0F;&#x4EE5;&#x53CA;&#x6570;&#x636E;&#x8FC7;&#x6EE4;&#xFF08;&#x8BF7;&#x53C2;&#x9605;&#x7EB9;&#x7406;&#x548C;&#x8868;&#x9762;&#x5185;&#x5B58;&#xFF09;&#x3002;</p>
<p>The global, constant, and texture memory spaces are persistent across kernel launches by the same application.</p>
<p>&#x5168;&#x5C40;&#x3001;&#x5E38;&#x91CF;&#x548C;&#x7EB9;&#x7406;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x5728;&#x540C;&#x4E00;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x7684;&#x5185;&#x6838;&#x542F;&#x52A8;&#x8FC7;&#x7A0B;&#x4E2D;&#x662F;&#x6301;&#x4E45;&#x7684;&#x3002;</p>
<p align="center">
 <img src="memory-hierarchy.png" alt="memory-hierarchy" title="memory-hierarchy" style="zoom:10%;">
</p>

<h5 id="heteroheneous-programming-&#x5F02;&#x6784;&#x7F16;&#x7A0B;">Heteroheneous Programming: &#x5F02;&#x6784;&#x7F16;&#x7A0B;</h5>
<p>As illustrated by Figure 7, the CUDA programming model assumes that the CUDA threads execute on a physically separate device that operates as a coprocessor to the host running the C++ program. This is the case, for example, when the kernels execute on a GPU and the rest of the C++ program executes on a CPU.
&#x5982;&#x56FE; 7 &#x6240;&#x793A;&#xFF0C;CUDA &#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x5047;&#x8BBE; CUDA &#x7EBF;&#x7A0B;&#x5728;&#x7269;&#x7406;&#x4E0A;&#x72EC;&#x7ACB;&#x7684;&#x8BBE;&#x5907;&#x4E0A;&#x6267;&#x884C;&#xFF0C;&#x8BE5;&#x8BBE;&#x5907;&#x4F5C;&#x4E3A;&#x8FD0;&#x884C; C++ &#x7A0B;&#x5E8F;&#x7684;&#x4E3B;&#x673A;&#x7684;&#x534F;&#x5904;&#x7406;&#x5668;&#x8FD0;&#x884C;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5F53;&#x5185;&#x6838;&#x5728; GPU &#x4E0A;&#x6267;&#x884C;&#x800C; C++ &#x7A0B;&#x5E8F;&#x7684;&#x5176;&#x4F59;&#x90E8;&#x5206;&#x5728; CPU &#x4E0A;&#x6267;&#x884C;&#x65F6;&#xFF0C;&#x5C31;&#x4F1A;&#x51FA;&#x73B0;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x3002;</p>
<p>The CUDA programming model also assumes that both the host and the device maintain their own separate memory spaces in DRAM, referred to as host memory and device memory, respectively. Therefore, a program manages the global, constant, and texture memory spaces visible to kernels through calls to the CUDA runtime (described in Programming Interface). This includes device memory allocation and deallocation as well as data transfer between host and device memory.
CUDA &#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x8FD8;&#x5047;&#x8BBE;&#x4E3B;&#x673A;&#x548C;&#x8BBE;&#x5907;&#x90FD;&#x5728; DRAM &#x4E2D;&#x7EF4;&#x62A4;&#x81EA;&#x5DF1;&#x72EC;&#x7ACB;&#x7684;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#xFF0C;&#x5206;&#x522B;&#x79F0;&#x4E3A;&#x4E3B;&#x673A;&#x5185;&#x5B58;&#x548C;&#x8BBE;&#x5907;&#x5185;&#x5B58;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x7A0B;&#x5E8F;&#x901A;&#x8FC7;&#x8C03;&#x7528; CUDA &#x8FD0;&#x884C;&#x65F6;&#xFF08;&#x5728;&#x7F16;&#x7A0B;&#x63A5;&#x53E3;&#x4E2D;&#x63CF;&#x8FF0;&#xFF09;&#x6765;&#x7BA1;&#x7406;&#x5185;&#x6838;&#x53EF;&#x89C1;&#x7684;&#x5168;&#x5C40;&#x3001;&#x5E38;&#x91CF;&#x548C;&#x7EB9;&#x7406;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x3002;&#x8FD9;&#x5305;&#x62EC;&#x8BBE;&#x5907;&#x5185;&#x5B58;&#x5206;&#x914D;&#x548C;&#x91CA;&#x653E;&#x4EE5;&#x53CA;&#x4E3B;&#x673A;&#x548C;&#x8BBE;&#x5907;&#x5185;&#x5B58;&#x4E4B;&#x95F4;&#x7684;&#x6570;&#x636E;&#x4F20;&#x8F93;&#x3002;</p>
<p>Unified Memory provides managed memory to bridge the host and device memory spaces. Managed memory is accessible from all CPUs and GPUs in the system as a single, coherent memory image with a common address space. This capability enables oversubscription of device memory and can greatly simplify the task of porting applications by eliminating the need to explicitly mirror data on host and device. See Unified Memory Programming for an introduction to Unified Memory.
&#x7EDF;&#x4E00;&#x5185;&#x5B58;&#x63D0;&#x4F9B;&#x6258;&#x7BA1;&#x5185;&#x5B58;&#x6765;&#x6865;&#x63A5;&#x4E3B;&#x673A;&#x548C;&#x8BBE;&#x5907;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x3002;&#x6258;&#x7BA1;&#x5185;&#x5B58;&#x53EF;&#x4F5C;&#x4E3A;&#x5177;&#x6709;&#x516C;&#x5171;&#x5730;&#x5740;&#x7A7A;&#x95F4;&#x7684;&#x5355;&#x4E2A;&#x4E00;&#x81F4;&#x5185;&#x5B58;&#x6620;&#x50CF;&#x4ECE;&#x7CFB;&#x7EDF;&#x4E2D;&#x7684;&#x6240;&#x6709; CPU &#x548C; GPU &#x8FDB;&#x884C;&#x8BBF;&#x95EE;&#x3002;&#x6B64;&#x529F;&#x80FD;&#x53EF;&#x5B9E;&#x73B0;&#x8BBE;&#x5907;&#x5185;&#x5B58;&#x7684;&#x8D85;&#x989D;&#x8BA2;&#x9605;&#xFF0C;&#x5E76;&#x4E14;&#x65E0;&#x9700;&#x5728;&#x4E3B;&#x673A;&#x548C;&#x8BBE;&#x5907;&#x4E0A;&#x663E;&#x5F0F;&#x955C;&#x50CF;&#x6570;&#x636E;&#xFF0C;&#x4ECE;&#x800C;&#x5927;&#x5927;&#x7B80;&#x5316;&#x79FB;&#x690D;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x7684;&#x4EFB;&#x52A1;&#x3002;&#x6709;&#x5173;&#x7EDF;&#x4E00;&#x5185;&#x5B58;&#x7684;&#x4ECB;&#x7ECD;&#xFF0C;&#x8BF7;&#x53C2;&#x9605;&#x7EDF;&#x4E00;&#x5185;&#x5B58;&#x7F16;&#x7A0B;&#x3002;</p>
<p align="center">
 <img src="heterogeneous-programming.png" style="zoom:70%;">
</p>

<p>Serial code executes on the host while parallel code executes on the device.
&#x4E32;&#x884C;&#x4EE3;&#x7801;&#x5728;&#x4E3B;&#x673A;&#x4E0A;&#x6267;&#x884C;&#xFF0C;&#x800C;&#x5E76;&#x884C;&#x4EE3;&#x7801;&#x5728;&#x8BBE;&#x5907;&#x4E0A;&#x6267;&#x884C;&#x3002;</p>
<h5 id="asynchronous-simt-programming-model-&#x5F02;&#x6B65;-simt-&#x7F16;&#x7A0B;&#x6A21;&#x578B;">Asynchronous SIMT Programming Model: &#x5F02;&#x6B65; SIMT &#x7F16;&#x7A0B;&#x6A21;&#x578B;</h5>
<p>In the CUDA programming model a thread is the lowest level of abstraction for doing a computation or a memory operation. Starting with devices based on the NVIDIA Ampere GPU architecture, the CUDA programming model provides acceleration to memory operations via the asynchronous programming model. The asynchronous programming model defines the behavior of asynchronous operations with respect to CUDA threads.</p>
<p>&#x5728; CUDA &#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x4E2D;&#xFF0C;&#x7EBF;&#x7A0B;&#x662F;&#x6267;&#x884C;&#x8BA1;&#x7B97;&#x6216;&#x5185;&#x5B58;&#x64CD;&#x4F5C;&#x7684;&#x6700;&#x4F4E;&#x62BD;&#x8C61;&#x7EA7;&#x522B;&#x3002;&#x4ECE;&#x57FA;&#x4E8E; NVIDIA Ampere GPU &#x67B6;&#x6784;&#x7684;&#x8BBE;&#x5907;&#x5F00;&#x59CB;&#xFF0C;CUDA &#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x901A;&#x8FC7;&#x5F02;&#x6B65;&#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x63D0;&#x4F9B;&#x5185;&#x5B58;&#x64CD;&#x4F5C;&#x52A0;&#x901F;&#x3002;&#x5F02;&#x6B65;&#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x5B9A;&#x4E49;&#x4E86;&#x4E0E; CUDA &#x7EBF;&#x7A0B;&#x76F8;&#x5173;&#x7684;&#x5F02;&#x6B65;&#x64CD;&#x4F5C;&#x7684;&#x884C;&#x4E3A;&#x3002;</p>
<p>The asynchronous programming model defines the behavior of <code>Asynchronous Barrier</code> for synchronization between CUDA threads. The model also explains and defines how <code>cuda::memcpy_async</code> can be used to move data asynchronously from global memory while computing in the GPU.</p>
<p>&#x5F02;&#x6B65;&#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x5B9A;&#x4E49;&#x4E86;&#x7528;&#x4E8E; CUDA &#x7EBF;&#x7A0B;&#x4E4B;&#x95F4;&#x540C;&#x6B65;&#x7684;&#x5F02;&#x6B65;&#x5C4F;&#x969C;&#x7684;&#x884C;&#x4E3A;&#x3002;&#x8BE5;&#x6A21;&#x578B;&#x8FD8;&#x89E3;&#x91CA;&#x5E76;&#x5B9A;&#x4E49;&#x4E86;&#x5982;&#x4F55;&#x4F7F;&#x7528;<code>cuda::memcpy_async</code>&#x5728; GPU &#x4E2D;&#x8BA1;&#x7B97;&#x65F6;&#x4ECE;&#x5168;&#x5C40;&#x5185;&#x5B58;&#x5F02;&#x6B65;&#x79FB;&#x52A8;&#x6570;&#x636E;&#x3002;</p>
<p>2.5.1. Asynchronous Operations</p>
<p>2.5.1.&#x5F02;&#x6B65;&#x64CD;&#x4F5C;</p>
<p>An asynchronous operation is defined as an operation that is initiated by a CUDA thread and is executed asynchronously as-if by another thread. In a well formed program one or more CUDA threads synchronize with the asynchronous operation. The CUDA thread that initiated the asynchronous operation is not required to be among the synchronizing threads.
&#x5F02;&#x6B65;&#x64CD;&#x4F5C;&#x88AB;&#x5B9A;&#x4E49;&#x4E3A;&#x7531; CUDA &#x7EBF;&#x7A0B;&#x53D1;&#x8D77;&#x5E76;&#x50CF;&#x7531;&#x53E6;&#x4E00;&#x4E2A;&#x7EBF;&#x7A0B;&#x4E00;&#x6837;&#x5F02;&#x6B65;&#x6267;&#x884C;&#x7684;&#x64CD;&#x4F5C;&#x3002;&#x5728;&#x683C;&#x5F0F;&#x826F;&#x597D;&#x7684;&#x7A0B;&#x5E8F;&#x4E2D;&#xFF0C;&#x4E00;&#x4E2A;&#x6216;&#x591A;&#x4E2A; CUDA &#x7EBF;&#x7A0B;&#x4E0E;&#x5F02;&#x6B65;&#x64CD;&#x4F5C;&#x540C;&#x6B65;&#x3002;&#x542F;&#x52A8;&#x5F02;&#x6B65;&#x64CD;&#x4F5C;&#x7684; CUDA &#x7EBF;&#x7A0B;&#x4E0D;&#x9700;&#x8981;&#x4F4D;&#x4E8E;&#x540C;&#x6B65;&#x7EBF;&#x7A0B;&#x4E2D;&#x3002;</p>
<p>Such an asynchronous thread (an as-if thread) is always associated with the CUDA thread that initiated the asynchronous operation. An asynchronous operation uses a synchronization object to synchronize the completion of the operation. Such a synchronization object can be explicitly managed by a user (e.g., cuda::memcpy_async) or implicitly managed within a library (e.g., cooperative_groups::memcpy_async).
&#x8FD9;&#x6837;&#x7684;&#x5F02;&#x6B65;&#x7EBF;&#x7A0B;&#xFF08;as-if &#x7EBF;&#x7A0B;&#xFF09;&#x59CB;&#x7EC8;&#x4E0E;&#x542F;&#x52A8;&#x5F02;&#x6B65;&#x64CD;&#x4F5C;&#x7684; CUDA &#x7EBF;&#x7A0B;&#x76F8;&#x5173;&#x8054;&#x3002;&#x5F02;&#x6B65;&#x64CD;&#x4F5C;&#x4F7F;&#x7528;&#x540C;&#x6B65;&#x5BF9;&#x8C61;&#x6765;&#x540C;&#x6B65;&#x64CD;&#x4F5C;&#x7684;&#x5B8C;&#x6210;&#x3002;&#x8FD9;&#x6837;&#x7684;&#x540C;&#x6B65;&#x5BF9;&#x8C61;&#x53EF;&#x4EE5;&#x7531;&#x7528;&#x6237;&#x663E;&#x5F0F;&#x7BA1;&#x7406;&#xFF08;&#x4F8B;&#x5982;&#xFF0C; cuda::memcpy_async &#xFF09;&#x6216;&#x5728;&#x5E93;&#x4E2D;&#x9690;&#x5F0F;&#x7BA1;&#x7406;&#xFF08;&#x4F8B;&#x5982;&#xFF0C; cooperative_groups::memcpy_async &#xFF09;&#x3002;</p>
<p>A synchronization object could be a cuda::barrier or a cuda::pipeline. These objects are explained in detail in Asynchronous Barrier and Asynchronous Data Copies using cuda::pipeline. These synchronization objects can be used at different thread scopes. A scope defines the set of threads that may use the synchronization object to synchronize with the asynchronous operation. The following table defines the thread scopes available in CUDA C++ and the threads that can be synchronized with each.
&#x540C;&#x6B65;&#x5BF9;&#x8C61;&#x53EF;&#x4EE5;&#x662F;cuda::barrier&#x6216;cuda::pipeline &#x3002;&#x8FD9;&#x4E9B;&#x5BF9;&#x8C61;&#x5728;&#x4F7F;&#x7528; cuda::pipeline &#x7684;&#x5F02;&#x6B65;&#x5C4F;&#x969C;&#x548C;&#x5F02;&#x6B65;&#x6570;&#x636E;&#x526F;&#x672C;&#x4E2D;&#x8BE6;&#x7EC6;&#x89E3;&#x91CA;&#x3002;&#x8FD9;&#x4E9B;&#x540C;&#x6B65;&#x5BF9;&#x8C61;&#x53EF;&#x4EE5;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x7EBF;&#x7A0B;&#x8303;&#x56F4;&#x5185;&#x4F7F;&#x7528;&#x3002;&#x8303;&#x56F4;&#x5B9A;&#x4E49;&#x4E86;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x540C;&#x6B65;&#x5BF9;&#x8C61;&#x6765;&#x4E0E;&#x5F02;&#x6B65;&#x64CD;&#x4F5C;&#x540C;&#x6B65;&#x7684;&#x7EBF;&#x7A0B;&#x96C6;&#x3002;&#x4E0B;&#x8868;&#x5B9A;&#x4E49;&#x4E86; CUDA C++ &#x4E2D;&#x53EF;&#x7528;&#x7684;&#x7EBF;&#x7A0B;&#x8303;&#x56F4;&#x4EE5;&#x53CA;&#x53EF;&#x4EE5;&#x4E0E;&#x6BCF;&#x4E2A;&#x7EBF;&#x7A0B;&#x540C;&#x6B65;&#x7684;&#x7EBF;&#x7A0B;&#x3002;</p>
<h5 id="compute-capability-&#x8BA1;&#x7B97;&#x80FD;&#x529B;">Compute Capability: &#x8BA1;&#x7B97;&#x80FD;&#x529B;</h5>
<h4 id="programming-interface-&#x7F16;&#x7A0B;&#x63A5;&#x53E3;">Programming Interface &#x7F16;&#x7A0B;&#x63A5;&#x53E3;</h4>
<h4 id="hardware-implementation-&#x786C;&#x4EF6;&#x5B9E;&#x73B0;">Hardware Implementation &#x786C;&#x4EF6;&#x5B9E;&#x73B0;</h4>
<h4 id="performance-guidelines-&#x6027;&#x80FD;&#x6307;&#x5357;">Performance Guidelines &#x6027;&#x80FD;&#x6307;&#x5357;</h4>
<hr>
<h2 id="ptx-parallel-thread-execution">PTX Parallel Thread Execution</h2>
<p>PTX: a low-level parallel thread execution virtual machine and instruction set architecture.</p>
<p>PTX &#x662F;&#x4E00;&#x79CD;&#x4F4E;&#x7EA7;&#x5E76;&#x884C;&#x7EBF;&#x7A0B;&#x6267;&#x884C;&#x865A;&#x62DF;&#x673A;&#x548C;&#x6307;&#x4EE4;&#x96C6;&#x4F53;&#x7CFB;&#x7ED3;&#x6784;&#x3002;</p>
<p>PTX exposes the GPU as data-parallel computing device.</p>
<h2 id="numba">Numba</h2>
<p>Overview&#xF0C1; &#x6982;&#x8FF0; &#xF0C1;</p>
<p>Numba supports CUDA GPU programming by directly compiling a restricted subset of Python code into CUDA kernels and device functions following the CUDA execution model. Kernels written in Numba appear to have direct access to NumPy arrays. NumPy arrays are transferred between the CPU and the GPU automatically.</p>
<p>Numba &#x901A;&#x8FC7;&#x5C06; Python &#x4EE3;&#x7801;&#x7684;&#x53D7;&#x9650;&#x5B50;&#x96C6;&#x76F4;&#x63A5;&#x7F16;&#x8BD1;&#x4E3A;&#x9075;&#x5FAA; CUDA &#x6267;&#x884C;&#x6A21;&#x578B;&#x7684; CUDA &#x5185;&#x6838;&#x548C;&#x8BBE;&#x5907;&#x51FD;&#x6570;&#x6765;&#x652F;&#x6301; CUDA GPU &#x7F16;&#x7A0B;&#x3002;&#x7528; Numba &#x7F16;&#x5199;&#x7684;&#x5185;&#x6838;&#x4F3C;&#x4E4E;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x8BBF;&#x95EE; NumPy &#x6570;&#x7EC4;&#x3002; NumPy &#x6570;&#x7EC4;&#x5728; CPU &#x548C; GPU &#x4E4B;&#x95F4;&#x81EA;&#x52A8;&#x4F20;&#x8F93;&#x3002;</p>
<h2 id="install-cuda">Install CUDA</h2>
<p><a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank">CUDA Toolkit Archive</a></p>
<p><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/" target="_blank">NVIDIA CUDA Installation Guide for Linux</a></p>
<h2 id="other-resources">Other Resources</h2>
<h3 id="programming-massively-parallel-processors-a-hands-on-approach">Programming Massively Parallel Processors: A Hands-on Approach</h3>
<p>Programming Massively Parallel Processors: A Hands-on Approach, Second Edition, teaches students how to program massively parallel processors. It offers a detailed discussion of various techniques for constructing parallel programs. Case studies are used to demonstrate the development process, which begins with computational thinking and ends with effective and efficient parallel programs. This guide shows both student and professional alike the basic concepts of parallel programming and GPU architecture. Topics of performance, floating-point format, parallel patterns, and dynamic parallelism are covered in depth. This revised edition contains more parallel programming examples, commonly-used libraries such as Thrust, and explanations of the latest tools. It also provides new coverage of CUDA 5.0, improved performance, enhanced development tools, increased hardware support, and more; increased coverage of related technology, OpenCL and new material on algorithm patterns, GPU clusters, host programming, and data parallelism; and two new case studies (on MRI reconstruction and molecular visualization) that explore the latest applications of CUDA and GPUs for scientific research and high-performance computing. This book should be a valuable resource for advanced students, software engineers, programmers, and hardware engineers.</p>
<p>Programming Massively Parallel Processors&#xFF1A; A Hands-on Approach&#xFF0C;&#x7B2C;&#x4E8C;&#x7248;&#xFF0C;&#x6559;&#x6388;&#x5B66;&#x751F;&#x5982;&#x4F55;&#x5BF9;&#x5927;&#x89C4;&#x6A21;&#x5E76;&#x884C;&#x5904;&#x7406;&#x5668;&#x8FDB;&#x884C;&#x7F16;&#x7A0B;&#x3002;&#x5B83;&#x8BE6;&#x7EC6;&#x8BA8;&#x8BBA;&#x4E86;&#x7528;&#x4E8E;&#x6784;&#x5EFA;&#x5E76;&#x884C;&#x7A0B;&#x5E8F;&#x7684;&#x5404;&#x79CD;&#x6280;&#x672F;&#x3002;&#x6848;&#x4F8B;&#x7814;&#x7A76;&#x7528;&#x4E8E;&#x6F14;&#x793A;&#x5F00;&#x53D1;&#x8FC7;&#x7A0B;&#xFF0C;&#x8BE5;&#x8FC7;&#x7A0B;&#x4ECE;&#x8BA1;&#x7B97;&#x601D;&#x7EF4;&#x5F00;&#x59CB;&#xFF0C;&#x4EE5;&#x6709;&#x6548;&#x548C;&#x9AD8;&#x6548;&#x7684;&#x5E76;&#x884C;&#x7A0B;&#x5E8F;&#x7ED3;&#x675F;&#x3002;&#x672C;&#x6307;&#x5357;&#x5411;&#x5B66;&#x751F;&#x548C;&#x4E13;&#x4E1A;&#x4EBA;&#x58EB;&#x5C55;&#x793A;&#x4E86;&#x5E76;&#x884C;&#x7F16;&#x7A0B;&#x548C; GPU &#x67B6;&#x6784;&#x7684;&#x57FA;&#x672C;&#x6982;&#x5FF5;&#x3002;&#x6DF1;&#x5165;&#x4ECB;&#x7ECD;&#x4E86;&#x6027;&#x80FD;&#x3001;&#x6D6E;&#x70B9;&#x683C;&#x5F0F;&#x3001;&#x5E76;&#x884C;&#x6A21;&#x5F0F;&#x548C;&#x52A8;&#x6001;&#x5E76;&#x884C;&#x6027;&#x7B49;&#x4E3B;&#x9898;&#x3002;&#x6B64;&#x4FEE;&#x8BA2;&#x7248;&#x5305;&#x542B;&#x66F4;&#x591A;&#x5E76;&#x884C;&#x7F16;&#x7A0B;&#x793A;&#x4F8B;&#x3001;&#x5E38;&#x7528;&#x5E93;&#xFF08;&#x5982; Thrust&#xFF09;&#x4EE5;&#x53CA;&#x6700;&#x65B0;&#x5DE5;&#x5177;&#x7684;&#x89E3;&#x91CA;&#x3002;&#x5B83;&#x8FD8;&#x63D0;&#x4F9B;&#x4E86; CUDA 5.0 &#x7684;&#x65B0;&#x8986;&#x76D6;&#x8303;&#x56F4;&#x3001;&#x6539;&#x8FDB;&#x7684;&#x6027;&#x80FD;&#x3001;&#x589E;&#x5F3A;&#x7684;&#x5F00;&#x53D1;&#x5DE5;&#x5177;&#x3001;&#x589E;&#x5F3A;&#x7684;&#x786C;&#x4EF6;&#x652F;&#x6301;&#x7B49;;&#x589E;&#x52A0;&#x4E86;&#x76F8;&#x5173;&#x6280;&#x672F;&#x3001;OpenCL &#x548C;&#x6709;&#x5173;&#x7B97;&#x6CD5;&#x6A21;&#x5F0F;&#x3001;GPU &#x96C6;&#x7FA4;&#x3001;&#x4E3B;&#x673A;&#x7F16;&#x7A0B;&#x548C;&#x6570;&#x636E;&#x5E76;&#x884C;&#x6027;&#x7684;&#x65B0;&#x6750;&#x6599;&#x7684;&#x8986;&#x76D6;&#x8303;&#x56F4;;&#x4EE5;&#x53CA;&#x4E24;&#x4E2A;&#x65B0;&#x7684;&#x6848;&#x4F8B;&#x7814;&#x7A76;&#xFF08;&#x5173;&#x4E8E; MRI &#x91CD;&#x5EFA;&#x548C;&#x5206;&#x5B50;&#x53EF;&#x89C6;&#x5316;&#xFF09;&#xFF0C;&#x63A2;&#x7D22; CUDA &#x548C; GPU &#x5728;&#x79D1;&#x5B66;&#x7814;&#x7A76;&#x548C;&#x9AD8;&#x6027;&#x80FD;&#x8BA1;&#x7B97;&#x4E2D;&#x7684;&#x6700;&#x65B0;&#x5E94;&#x7528;&#x3002;&#x8FD9;&#x672C;&#x4E66;&#x5E94;&#x8BE5;&#x662F;&#x9AD8;&#x7EA7;&#x5B66;&#x751F;&#x3001;&#x8F6F;&#x4EF6;&#x5DE5;&#x7A0B;&#x5E08;&#x3001;&#x7A0B;&#x5E8F;&#x5458;&#x548C;&#x786C;&#x4EF6;&#x5DE5;&#x7A0B;&#x5E08;&#x7684;&#x5B9D;&#x8D35;&#x8D44;&#x6E90;&#x3002;</p>
<h3 id="cuda-examples">CUDA Examples</h3>
<pre class="language-"><code class="lang-c++">#include <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>cuda_runtime.h</span><span class="token punctuation">&gt;</span></span>
#include <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>iostream</span><span class="token punctuation">&gt;</span></span>

// CUDA kernel function for vector addition
__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {
    int i = blockIdx.x * blockDim.x + threadIdx.x; // Calculate global thread index
    if (i &lt; N) {
        C[i] = A[i] + B[i];
    }
}

int main() {
    int N = 1024;
    size_t size = N * sizeof(float);

    // Allocate host memory
    float *h_A = (float*)malloc(size);
    float *h_B = (float*)malloc(size);
    float *h_C = (float*)malloc(size);

    // Initialize vectors
    for (int i = 0; i &lt; N; i++) {
        h_A[i] = static_cast<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>float</span><span class="token punctuation">&gt;</span></span>(i);
        h_B[i] = static_cast<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>float</span><span class="token punctuation">&gt;</span></span>(i * 2);
    }

    // Allocate device memory
    float *d_A, *d_B, *d_C;
    cudaMalloc((void**)&amp;d_A, size);
    cudaMalloc((void**)&amp;d_B, size);
    cudaMalloc((void**)&amp;d_C, size);

    // Copy data from host to device
    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);

    // Launch kernel
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    vectorAdd&lt;&lt;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>blocksPerGrid,</span> <span class="token attr-name">threadsPerBlock</span><span class="token punctuation">&gt;</span></span>&gt;&gt;(d_A, d_B, d_C, N);

    // Copy result back to host
    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);

    // Print some results
    for (int i = 0; i &lt; 10; i++) {
        std::cout &lt;&lt; h_C[i] &lt;&lt; std::endl;
    }

    // Free memory
    free(h_A); free(h_B); free(h_C);
    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);

    return 0;
}
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../LearnConda/Conda.html" class="navigation navigation-prev " aria-label="Previous page: Learn Conda">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../LearnCV/ComputerVisoin.html" class="navigation navigation-next " aria-label="Next page: Learn Computer Vision">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Learn CUDA","level":"1.2.3","depth":2,"next":{"title":"Learn Computer Vision","level":"1.2.4","depth":2,"path":"Learn/LearnCV/ComputerVisoin.md","ref":"Learn/LearnCV/ComputerVisoin.md","articles":[]},"previous":{"title":"Learn Conda","level":"1.2.2","depth":2,"path":"Learn/LearnConda/Conda.md","ref":"Learn/LearnConda/Conda.md","articles":[]},"dir":"ltr"},"config":{"plugins":["include-codeblock","-lunr","-search","search-pro","expandable-chapters","code","chapter-fold","splitter","github","-highlight","prism","prism-themes","theme-comscore","katex-pp"],"styles":{"pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css","website":"styles/website.css"},"pluginsConfig":{"chapter-fold":{},"prism":{"lang":{"shell":"bash"},"css":["prism-themes/themes/prism-synthwave84.css"]},"github":{"url":"https://github.com/houhuawei23/Notes"},"splitter":{},"search-pro":{},"code":{"copyButtons":true},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-comscore":{},"prism-themes":{},"include-codeblock":{"check":false,"edit":false,"fixlang":false,"lang":"","template":"default","theme":"chrome","unindent":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"katex-pp":{},"theme-default":{"styles":{"pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css","website":"styles/website.css"},"showLevel":false},"expandable-chapters":{}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"Introduction.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"language":"cn","gitbook":"*","description":"This is such a great book!"},"file":{"path":"Learn/LearnCUDA/CUDA.md","mtime":"2024-12-29T11:42:16.336Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2024-12-29T11:43:04.527Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="../../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-chapter-fold/chapter-fold.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-theme-comscore/test.js"></script>
        
    

    </body>
</html>

